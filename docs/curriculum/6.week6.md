> [ðŸ”¼ README](../../README.md)

### Week 6 â€” Day-by-Day Breakdown

## Week 6 Theme: Regression Deep Dive ðŸ“ˆ

**Goal (by end of Week 6):**

- Understand what regression is optimizing (math + intuition)
- Build a reliable linear regression pipeline (baseline â†’ diagnostics â†’ fixes â†’ regularization â†’ final)
- Defend modeling decisions with evidence (assumptions, residuals, CV, stability, error analysis)

## Week 6 â€” Day 1 âœ…  

- ***Focus: Regression From Scratch (No Libraries)***
- Built a linear model manually: y_hat = w*x + b
- Defined Mean Squared Error (MSE) and why it punishes large errors more.
- Implemented gradient descent updates for w and b (learned how learning rate affects convergence).
- Visualized:
  - Loss curve vs iterations
  - Best-fit line vs scatter points

âœ… **Outcome:** You can explain what regression is optimizing and implement a working linear regressor with only NumPy.

**Checkpoint Questions:**

- What happens if you scale feature x by 100? (connect to learning rate + scaling)
- What does it mean if the loss explodes?

---

## Week 6 â€” Day 2 âœ…  

- ***Focus: Baseline Regression + Correct Evaluation Flow***
- Established a regression baseline (mean predictor) to validate that the model adds real value.
- Implemented train/validation/test split with a clean workflow.
- Trained `LinearRegression` in scikit-learn.
- Computed and interpreted regression metrics:
  - MAE
  - MSE
  - RMSE
  - R^2
- Plotted predicted vs actual and residuals.

âœ… **Outcome:** You can build a clean baseline regression model and interpret metrics properly.

**Checkpoint Questions:**

- When would MAE be better than RMSE as your primary metric?
- What does a negative R^2 imply?

---

## Week 6 â€” Day 3 âœ…  

- ***Focus: Statsmodels OLS + Interpreting Coefficients***
- Fit an OLS regression using statsmodels.
- Read and interpreted:
  - Coefficients and confidence intervals
  - p-values (and why theyâ€™re often misused)
  - Adjusted R^2
- Wrote â€œinterpretation statementsâ€ of coefficients:
  - â€œIf X increases by 1 unit, predicted Y changes by â€¦ (holding others constant)â€

âœ… **Outcome:** You can interpret regression outputs beyond just performance numbers.

**Checkpoint Questions:**

- Why can a statistically significant coefficient still be practically useless?

---

## Week 6 â€” Day 4 âœ…  

- ***Focus: Regression Diagnostics (Assumptions + Residual Thinking)***
- Built a reusable diagnostic checklist using plots and tests.
- Performed residual diagnostics:
  - Residuals vs fitted (non-linearity clues)
  - Histogram / QQ-style check (when normality matters)
  - Heteroskedasticity patterns (fan shape)
- Identified influence/outliers:
  - Leverage
  - Cookâ€™s distance
- Checked multicollinearity:
  - Correlation heatmap
  - VIF calculation

âœ… **Outcome:** You can detect when linear regression assumptions are being violated and explain why it matters.

**Checkpoint Questions:**

- Which assumption violations hurt prediction the most vs inference the most?

---

## Week 6 â€” Day 5 âœ…  

- ***Focus: Fixes (Transforms, Interactions, Polynomial Features)***
- Applied targeted fixes instead of â€œrandom feature chaos.â€
- Tried:
  - Log transform on skewed variables (feature or target)
  - Interaction features (X1 * X2)
  - Polynomial features (degree 2â€“3)
- Evaluated improvements on validation set only.
- Documented why each transformation made sense using plots.

âœ… **Outcome:** You can improve regression fit while controlling overfitting risk.

**Checkpoint Questions:**

- What evidence would convince you a transformation is justified?

---

## Week 6 â€” Day 6 âœ…  

- ***Focus: Regularization (Ridge, Lasso, Elastic Net) + CV***
- Standardized numeric features correctly.
- Trained and tuned:
  - RidgeCV
  - LassoCV
  - ElasticNetCV
- Compared:
  - Metrics vs baseline
  - Coefficient stability
  - Impact on multicollinearity
- Learned how regularization controls model complexity and improves stability.

âœ… **Outcome:** You can choose and tune regularized regression models and explain the tradeoffs.

**Checkpoint Questions:**

- Why does Lasso sometimes choose one of two correlated features â€œarbitrarilyâ€?
- What does Ridge do to coefficients compared to Lasso?

---

## Week 6 â€” Day 7 âœ…  

- ***Capstone: End-to-End Regression Workflow (Model Defense)***
- Built a full regression project with the same rigor as Week 5â€™s mini-project:
  1) Baseline model + metrics
  2) Diagnostics (residuals, VIF, influence)
  3) Apply 1â€“2 improvements (transforms/interactions/polynomial and/or regularization)
  4) Cross-validated selection
  5) Final test evaluation
  6) â€œModel Defenseâ€ write-up:
     - Why this model
     - What risks remain
     - What to monitor in production (drift, input ranges, error slices)

âœ… **Outcome:** Completed an end-to-end regression pipeline with evidence-based model selection and a clear defense.

---

### Core Libraries and Setup

```bash
source .venv/bin/activate
pip install -U pip
pip install numpy pandas matplotlib scikit-learn statsmodels scipy
pip freeze > requirements.txt
```

---

## Key Skills

### Regression Foundations

- Linear model, MSE, gradient descent
- Scaling impact on optimization

### Evaluation

- MAE, MSE, RMSE, \(R^2\)
- Residual analysis and prediction sanity checks

### Diagnostics

- Non-linearity detection
- Heteroskedasticity recognition
- Outliers & influence (leverage, Cookâ€™s distance)
- Multicollinearity (correlation + VIF)

### Improvement & Optimization

- Feature transforms (log)
- Interactions, polynomial features
- Regularization (Ridge/Lasso/ElasticNet)
- Cross-validation and stability checks

---

### Examples

#### Example 1 â€” From Scratch (Gradient Descent Skeleton)

```python
import numpy as np

# y_hat = w*x + b
# loss = mean((y - y_hat)^2)

w, b = 0.0, 0.0
lr = 0.01

for step in range(1000):
    y_hat = w * X + b
    error = y_hat - y
    loss = np.mean(error ** 2)

    # gradients
    dw = 2 * np.mean(error * X)
    db = 2 * np.mean(error)

    w -= lr * dw
    b -= lr * db
```

#### Example 2 â€” Scikit-learn Regression Pipeline

```python
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
import pandas as pd

df = pd.read_csv('data.csv')

num_cols = ['feature1', 'feature2']
cat_cols = ['category1']

tf = ColumnTransformer([
    ('num', StandardScaler(), num_cols),
    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)
])

pipe = Pipeline([
    ('prep', tf),
    ('model', LinearRegression())
])

X = df[num_cols + cat_cols]
y = df['target']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
pipe.fit(X_train, y_train)
print('Train R2:', pipe.score(X_train, y_train))
print('Test R2:', pipe.score(X_test, y_test))
```

#### Example 3 â€” Regularized Regression (RidgeCV)

```python
from sklearn.linear_model import RidgeCV
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

ridge = Pipeline([
    ('scale', StandardScaler(with_mean=False)),
    ('model', RidgeCV(alphas=[0.1, 1.0, 10.0, 100.0]))
])

ridge.fit(X_train_processed, y_train)
print('Best alpha:', ridge.named_steps['model'].alpha_)
```

---
