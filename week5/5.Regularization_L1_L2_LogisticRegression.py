''' *** Week 5 ¬∑ Day 5 ‚Äî Regularization (L1 & L2) in Logistic Regression

üéØ Learning Goal

By the end of today, we will clearly understand:
	‚Ä¢	Why unregularized logistic regression is dangerous
	‚Ä¢	What overfitting really means in coefficient space
	‚Ä¢	How L2 (Ridge) and L1 (Lasso) behave differently
	‚Ä¢	What the parameter C actually controls
	‚Ä¢	Why regularization is not optional in real systems

'''

import pandas as pd
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import RobustScaler,OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report

titdf = pd.read_csv('./data/week5/titanic_synthetic.csv')

num_cols = ['Age','Fare']
cat_cols = ['Embarked','Sex']
features = num_cols + cat_cols
target  = 'Survived'

num_pipe = Pipeline([
    ('impute',SimpleImputer(strategy='median')),
    ('scaler',RobustScaler())
])

cat_pipe = Pipeline([
    ('impute',SimpleImputer(strategy='most_frequent')),
    ('encode',OneHotEncoder(handle_unknown='ignore'))
])

pre_prcsr = ColumnTransformer([
    ('nums',num_pipe,num_cols),
    ('catg',cat_pipe,cat_cols)
])


X = titdf[features]
Y = titdf[target]

X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=42)

#L2 Regularization
model_l2 = LogisticRegression(
    penalty='l2',
    C=1,
    max_iter=1000,
    solver='lbfgs'
)

l2_pipe = Pipeline([
    ('preprcsr',pre_prcsr),
    ('model',model_l2)
])

l2_pipe.fit(X_train,Y_train)

l2_feature_names = l2_pipe.named_steps['preprcsr'].get_feature_names_out()
l2_coef= l2_pipe.named_steps['model'].coef_[0]

l2_coef_df  = (
    pd.DataFrame({'features':l2_feature_names, 'coef':l2_coef}).sort_values(by='coef', key=abs, ascending=False)
)
# print(l2_coef_df)


#L1 Regularization
model_l1 = LogisticRegression(
    penalty='l1',
    C=1,
    max_iter=1000,
    solver='liblinear'
)

l1_pipe = Pipeline([
    ('preprcsr',pre_prcsr),
    ('model',model_l1)
])

l1_pipe.fit(X_train,Y_train)

l1_feature_names = l1_pipe.named_steps['preprcsr'].get_feature_names_out()
l1_coef= l1_pipe.named_steps['model'].coef_[0]

l1_coef_df  = (
    pd.DataFrame({'features':l1_feature_names, 'coef':l1_coef}).sort_values(by='coef', key=abs, ascending=False)
)
# print('\n\n\n\n',l1_coef_df)


#Varying C
for c in [0.01,0.1,1,30,100]:
    model = LogisticRegression(
        penalty='l1',
        C=c,
        max_iter=1000,
        solver='liblinear'
    )

    c_pipe = Pipeline([
        ('preprcsr',pre_prcsr),
        ('model',model)
    ])

    c_pipe.fit(X_train,Y_train)
    cYpred = c_pipe.predict(X_test)
    print(f'\n C={c} ‚Üí non-zero coefficients: '
          ,(c_pipe.named_steps['model'].coef_[0])
          ,'\n Feature Names: ',l1_feature_names
          , '\n Accuracy Score --> ', accuracy_score(Y_test,cYpred) 
          ,'\n Classification Report --> \n',classification_report(Y_test,cYpred)
          ,'\n\n\n'
          )


'''  ** Theory
1Ô∏è‚É£ Why Regularization Exists (the real reason)

Recall the logistic regression objective:

Loss = Log Loss

Unregularized logistic regression tries to:

Push coefficients as far as needed to reduce classification error.

Problem:

If features are:
	‚Ä¢	correlated
	‚Ä¢	noisy
	‚Ä¢	weakly predictive

the model can:
	‚Ä¢	inflate coefficients
	‚Ä¢	become unstable
	‚Ä¢	overfit noise
	‚Ä¢	behave badly on new data

This is not theoretical ‚Äî it happens all the time.

‚∏ª

2Ô∏è‚É£ Regularization = Constraint on Coefficients

Regularization adds a penalty term:

** L2 (Ridge)
-------------
∆õ --> lambda
‚àë --> sum

Loss = Log Loss + ∆õ ‚àë w^2

** L1 (Lasso)
-------------
|w| --> Absolute value of weight

Loss = Log Loss + ∆õ ‚àë |w|


Interpretation (important):

Regularization tells the model:
‚ÄúFit the data ‚Äî but don‚Äôt be overly confident unless you really must.‚Äù

‚∏ª

3Ô∏è‚É£ What C Actually Means (this is critical)

In scikit-learn:
LogisticRegression(C=1.0)

C is inverse regularization strength:

C value             Meaning
--------            --------
Small C (0.01)      Strong regularization
Medium C (1.0)      Balanced
Large C (100)       Almost no regularization

So:
	‚Ä¢	Lower C ‚Üí simpler model
	‚Ä¢	Higher C ‚Üí more flexible model

This is the opposite of how Œª is written in math books ‚Äî keep that straight.

‚∏ª

4Ô∏è‚É£ L2 Regularization (Ridge): ‚ÄúShrink, don‚Äôt kill‚Äù

Behavior:
	‚Ä¢	Shrinks all coefficients
	‚Ä¢	Keeps all features
	‚Ä¢	Rarely sets anything to exactly zero

Intuition:

‚ÄúEvery feature can contribute ‚Äî but none too much.‚Äù

When L2 is preferred:
	‚Ä¢	Correlated features
	‚Ä¢	When you believe most features matter
	‚Ä¢	When stability matters more than sparsity

‚∏ª

5Ô∏è‚É£ L1 Regularization (Lasso): ‚ÄúSelect, then fit‚Äù

Behavior:
	‚Ä¢	Drives some coefficients to exactly zero
	‚Ä¢	Performs implicit feature selection

Intuition:

‚ÄúOnly a few features deserve to exist.‚Äù

When L1 is preferred:
	‚Ä¢	High-dimensional data
	‚Ä¢	Many irrelevant features
	‚Ä¢	You want interpretability
	‚Ä¢	You want sparsity

6Ô∏è‚É£ Key Conceptual Takeaways
	‚Ä¢	Regularization controls model confidence
	‚Ä¢	L2 = smooth, stable, conservative
	‚Ä¢	L1 = aggressive, selective, sparse
	‚Ä¢	C controls how much the model is allowed to ‚Äúbelieve itself‚Äù
	‚Ä¢	Regularization changes interpretation of coefficients, not just accuracy

        Q)  we didnt see any change in behvaior espeically accuracy score and classification report (precision, recall, f1 score) with varying C and l1 penalty for the model) why is that
        egularization strongly affects coefficients, but often has little or no effect on accuracy / precision / recall ‚Äî especially in simple, well-specified problems.

        Let‚Äôs unpack this carefully.

        ‚∏ª

        1Ô∏è‚É£ Key principle (anchor this)

        Metrics measure predictions.
        Regularization mainly reshapes coefficients.

        If reshaping coefficients does not change the predicted probabilities enough to cross decision thresholds, then:
            ‚Ä¢	accuracy
            ‚Ä¢	precision
            ‚Ä¢	recall
            ‚Ä¢	F1

        will remain almost identical.

        That‚Äôs exactly what you saw.

        ‚∏ª

        2Ô∏è‚É£ Why this happened in your case (specific, not generic)

        Your setup has these properties:

        ‚úî Few features
            ‚Ä¢	Age
            ‚Ä¢	Fare
            ‚Ä¢	Sex
            ‚Ä¢	Embarked

        This is a low-dimensional problem.

        ‚∏ª

        ‚úî Strong, clean signal
            ‚Ä¢	Sex is dominant
            ‚Ä¢	Embarked_C is clear
            ‚Ä¢	Age & Fare are consistent

        There is no feature explosion, no noise swamp.

        ‚∏ª

        ‚úî Balanced dataset
            ‚Ä¢	~50/50 survival
            ‚Ä¢	No extreme class imbalance
            ‚Ä¢	Default threshold works well

        ‚∏ª

        ‚úî Logistic regression already near optimal

        Even unregularized, the model:
            ‚Ä¢	is not overfitting
            ‚Ä¢	is not unstable
            ‚Ä¢	is not memorizing noise

        So when you add L1/L2:
            ‚Ä¢	coefficients shrink
            ‚Ä¢	some drop out
            ‚Ä¢	but decision boundaries barely move

        ‚∏ª

        3Ô∏è‚É£ Why predictions didn‚Äôt change even when coefficients did

        This is subtle but crucial.

        Logistic regression predicts:

        \sigma(w_0 + w_1 x_1 + w_2 x_2 + \dots)

        If:
            ‚Ä¢	coefficients shrink proportionally
            ‚Ä¢	dominant features remain dominant
            ‚Ä¢	relative ordering of samples stays the same

        Then:

        Probabilities shift slightly, but rankings stay the same.

        And if rankings stay the same:
            ‚Ä¢	ROC stays the same
            ‚Ä¢	Threshold-based predictions stay the same
            ‚Ä¢	Metrics stay the same

        This is why:
            ‚Ä¢	AUC barely moved
            ‚Ä¢	Accuracy barely moved
            ‚Ä¢	Precision/Recall barely moved

        ‚∏ª

        4Ô∏è‚É£ Why this is actually a good sign

        Many learners expect:

        ‚ÄúRegularization should improve accuracy‚Äù

        That is not the main purpose of regularization.

        Regularization‚Äôs real goals:
            ‚Ä¢	improve generalization
            ‚Ä¢	improve stability
            ‚Ä¢	prevent coefficient explosion
            ‚Ä¢	handle future noise

        Not necessarily:
            ‚Ä¢	improve training or test accuracy

        In clean problems, regularization is preventive, not corrective.

        ‚∏ª

        5Ô∏è‚É£ When you would see metric changes

        You would see noticeable metric changes if any of these were true:

        üî• High dimensionality
            ‚Ä¢	100s / 1000s of features

        üî• Strong multicollinearity
            ‚Ä¢	Many correlated numeric variables

        üî• Noisy or weak signals
            ‚Ä¢	True signal barely above noise

        üî• Severe class imbalance
            ‚Ä¢	Threshold sensitivity amplified

        üî• Very small dataset
            ‚Ä¢	Overfitting becomes visible

        Your current dataset has none of these problems.

        So the lack of metric change is expected and correct.

        ‚∏ª

        6Ô∏è‚É£ L1 vs L2: why metrics stayed similar even when features dropped

        You saw:
            ‚Ä¢	L1 dropped features
            ‚Ä¢	L2 kept all features
            ‚Ä¢	Metrics stayed similar

        Why?

        Because:
            ‚Ä¢	Dropped features were redundant
            ‚Ä¢	Surviving features captured most of the signal
            ‚Ä¢	Decision surface didn‚Äôt change meaningfully

        This is a classic case of:

        Multiple models with different explanations but similar predictive power

        That‚Äôs very common in ML.

        ‚∏ª

        7Ô∏è‚É£ This is an important real-world lesson

        Do not judge regularization by accuracy alone.

        Regularization is about:
            ‚Ä¢	robustness
            ‚Ä¢	interpretability
            ‚Ä¢	stability under data shift
            ‚Ä¢	confidence control

        A model that:
            ‚Ä¢	performs the same today
            ‚Ä¢	but is more stable tomorrow

        is a better model, even if metrics are identical.

        ‚∏ª

        8Ô∏è‚É£ One-line summary (bookmark this)

        Regularization changes how the model reasons, not necessarily what it predicts ‚Äî especially when the problem is simple and well-specified.

'''