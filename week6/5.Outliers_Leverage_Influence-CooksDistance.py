'''Week 6 Â· Day 5 â€” Outliers, Leverage, Influence (Cookâ€™s Distance)

Topics
	â€¢	What residual â€œoutliersâ€ are vs what â€œinfluentialâ€ points are
	â€¢	Leverage: unusual X values (feature-space extremes)
	â€¢	Influence: points that can noticeably change our fitted line/model
	â€¢	Cookâ€™s Distance, leverage (hat values), studentized residuals
	â€¢	How we decide what to investigate (not auto-delete rows)

ğŸ¯ Learning Goals

By the end of Day 5, we will be able to:
	â€¢	Explain the difference between:
	â€¢	large residuals (badly predicted)
	â€¢	high leverage (unusual inputs)
	â€¢	high influence (changes the model)
	â€¢	Compute and visualize:
	â€¢	Cookâ€™s Distance
	â€¢	leverage (hat values)
	â€¢	studentized residuals
	â€¢	Identify the top influential rows and inspect them safely
	â€¢	Decide what we would try next (robust models, transforms, feature work), without blindly removing data

'''

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import statsmodels.api as sm

from sklearn.model_selection import train_test_split
from sklearn.datasets import fetch_california_housing

# ==========================================================
# Step 1 â€” Fit an OLS model on our training Set
# ==========================================================

chdf = fetch_california_housing(as_frame=True).frame
'''
print("\n==============================================================================")
print(chdf.info())
'''

target='MedHouseVal'
X = chdf.drop(columns=[target])
Y = chdf[target]

X_trainval,X_test,Y_trainval,Y_test = train_test_split(X,Y,test_size=0.2,random_state=42)
X_train,X_val,Y_train,Y_val = train_test_split(X_trainval,Y_trainval,test_size=0.2,random_state=42)

X_train_sm = sm.add_constant(X_train)
ols = sm.OLS(Y_train,X_train_sm).fit()

'''
print("\n==============================================================================")
print("R2:",ols.rsquared)
print("Adj R2:",ols.rsquared_adj)

R2: 0.6131488911003316
Adj R2: 0.6129144358828167
'''


# ==========================================================
# Step 2 â€” Compute influence metrics (Cookâ€™s D, leverage, studentized residuals)
# ==========================================================

influence = ols.get_influence()

# Core diagnostics
cooks_d = influence.cooks_distance[0]          # array
leverage = influence.hat_matrix_diag           # array
stud_resid = influence.resid_studentized_internal  # array


'''
print("\n==============================================================================")
print("\nDiagnostics arrays:")
print("Cook's D shape:", cooks_d.shape)
print("Leverage shape:", leverage.shape)
print("Studentized residual shape:", stud_resid.shape)

Diagnostics arrays:
Cook's D shape: (13209,)
Leverage shape: (13209,)
Studentized residual shape: (13209,)

What each one means (simple)
	â€¢	Studentized residual: â€œhow extreme is the errorâ€ after scaling (like a normalized residual)
	â€¢	Leverage: â€œhow unusual is this X row compared to othersâ€
	â€¢	Cookâ€™s D: â€œif we removed this row, how much would the model change?â€

'''

# ==========================================================
# Step 3 â€” Plot Cookâ€™s Distance (who are the top influencers?)
# ==========================================================
plt.figure()
plt.stem(np.arange(len(cooks_d)), cooks_d)  # stems help us see spikes
plt.xlabel("Row index (train)")
plt.ylabel("Cook's Distance")
plt.title("Cook's Distance â€” Training Set")
plt.savefig("week6/5.1CooksDistancePlot.png")
# plt.show()


# ~~~ Now we'll find the top 10 influential points:
top_k = 10
top_idx = np.argsort(cooks_d)[-top_k:][::-1]

'''
print("\n==============================================================================")
print("Top influential points by Cook's D:")
for rank, idx in enumerate(top_idx, 1):
    print(f"{rank:2d}) idx={idx}  CookD={cooks_d[idx]:.6f}  leverage={leverage[idx]:.6f}  stud_resid={stud_resid[idx]:.3f}")


Top influential points by Cook's D:
 1) idx=2757  CookD=2.001294  leverage=0.576413  stud_resid=3.638
 2) idx=2580  CookD=1.904147  leverage=0.403434  stud_resid=5.034
 3) idx=225  CookD=0.484712  leverage=0.117223  stud_resid=-5.732
 4) idx=10876  CookD=0.135771  leverage=0.067223  stud_resid=4.118
 5) idx=3798  CookD=0.123410  leverage=0.054898  stud_resid=-4.373
 6) idx=9659  CookD=0.051227  leverage=0.051593  stud_resid=2.911
 7) idx=1080  CookD=0.037541  leverage=0.004830  stud_resid=-8.343
 8) idx=4023  CookD=0.036925  leverage=0.033731  stud_resid=-3.085
 9) idx=10332  CookD=0.036688  leverage=0.033101  stud_resid=-3.106
10) idx=2308  CookD=0.026171  leverage=0.047587  stud_resid=-2.171
'''

# ==========================================================
# Step 4 â€” Inspect the top influencer points
# ==========================================================
top_rows = X_train.iloc[top_idx].copy()
top_rows["y_train"] = Y_train.iloc[top_idx].values
top_rows["CookD"] = cooks_d[top_idx]
top_rows["Leverage"] = leverage[top_idx]
top_rows["StudResid"] = stud_resid[top_idx]

'''
print("\n==============================================================================")
print("\nTop rows (first 5 shown):")
print(top_rows.head())


Top rows (first 5 shown):
       MedInc  HouseAge   AveRooms  AveBedrms  Population  ...  Longitude  y_train     CookD  Leverage  StudResid
3364   5.5179      36.0   5.142857   1.142857      4198.0  ...    -120.51    0.675  2.001294  0.576413   3.638153
16669  4.2639      46.0   9.076923   1.307692      6532.0  ...    -120.70    3.500  1.904147  0.403434   5.034018
11862  2.6250      25.0  59.875000  15.312500        28.0  ...    -121.25    0.675  0.484712  0.117223  -5.731689
1913   4.0714      19.0  61.812500  11.000000       112.0  ...    -120.06    4.375  0.135771  0.067223   4.117704
1102   2.4028      17.0  31.777778   9.703704        47.0  ...    -121.54    0.675  0.123410  0.054898  -4.372778

[5 rows x 12 columns]

What weâ€™re looking for
	â€¢	Extremely high/low MedInc, rooms/bedrooms ratios, unusual geo coords, etc.
	â€¢	Rows that look â€œweirdâ€ (possible data artifacts) vs â€œrare but validâ€ cases
'''

# ==========================================================
# Step 5 â€” A useful combined diagnostic plot
# ==========================================================
plt.figure()
plt.scatter(leverage, stud_resid, s=20)
plt.xlabel("Leverage")
plt.ylabel("Studentized Residual")
plt.title("Leverage vs Studentized Residual (Training)")
plt.axhline(0)
plt.savefig("week6/5.2Leverage_StudentizedResidual.png")
# plt.show()

'''
Interpretation:
	â€¢	high leverage + large |studentized residual| are the most suspicious
	â€¢	Cookâ€™s D helps quantify overall influence
'''


# ==========================================================
# RETROSPECTION
# ==========================================================
'''
Understand more about the metrics
        * How its calculated
        * What is the expected value
        * What values are considered as deviations and how to measure. (Close, too big, too small)

    A) Stundentized Residual
        
        Letâ€™s make it concrete with one row

        Pick any index i (weâ€™ll use the â€œtop Cookâ€™s Dâ€ indices soon). For that i:

        A) Studentized residual (error extremeness)
            â€¢	residual = pred - actual
            â€¢	studentized residual = residual divided by an estimate of its standard deviation

        So itâ€™s like a z-score for errors:
            â€¢	stud_resid = 0 â†’ prediction is basically on target
            â€¢	stud_resid = 2.5 â†’ about 2.5 â€œstandard error unitsâ€ off (pretty large)
            â€¢	stud_resid = -3.0 â†’ very underpredicted

        Rule of thumb:
            â€¢	|stud_resid| > 2 is worth looking at
            â€¢	|stud_resid| > 3 is very suspicious

    B) Leverage (X unusualness)

        Leverage is: â€œis this rowâ€™s X far from the center of the X cloud?â€
            â€¢	high leverage means the feature combination is rare/extreme (unusual latitude/longitude, extreme MedInc, extreme room ratios, etc.)

        Rule of thumb:
            â€¢	average leverage â‰ˆ (p + 1) / n
        where p = number of features, +1 for intercept
        Here p=8 (we have 8 features in our california housing dataset),
        so average â‰ˆ 9/13209 â‰ˆ 0.00068
            â€¢	values several times larger than that (like >0.005 or >0.01) are â€œhighâ€ relative to the average

    C) Cookâ€™s D (overall influence)

        Cookâ€™s D combines both:
            â€¢	high leverage (unusual X)
            â€¢	and/or high residual (big error)

        Cookâ€™s D answers:

        â€œIf we remove this row and refit, how much would the fitted model change overall?â€

        Rule of thumb:
            â€¢	CookD > 4/n is often used as a â€œflagâ€
        here 4/13209 â‰ˆ 0.00030
        (not a hard rule â€” just a trigger to inspect)

â¸»

    Why these three are different (simple scenarios)

    Scenario 1: Big error but normal X
        â€¢	high |stud_resid|
        â€¢	low/moderate leverage
        â€¢	CookD might be moderate
    Meaning: the model struggles on this case, but removing it wonâ€™t change the model much.

    Scenario 2: Weird X but model predicts it well
        â€¢	low |stud_resid|
        â€¢	high leverage
        â€¢	CookD can still be noticeable
    Meaning: itâ€™s an extreme input. Even if it fits well, it can â€œanchorâ€ the line.

    Scenario 3: Weird X AND big error (most dangerous)
        â€¢	high |stud_resid|
        â€¢	high leverage
        â€¢	high CookD
    Meaning: this row can pull the model and distort coefficients.

â¸»

    Top influential points by Cook's D:
    1) idx=2757  CookD=2.001294  leverage=0.576413  stud_resid=3.638
    2) idx=2580  CookD=1.904147  leverage=0.403434  stud_resid=5.034
    3) idx=225  CookD=0.484712  leverage=0.117223  stud_resid=-5.732
    4) idx=10876  CookD=0.135771  leverage=0.067223  stud_resid=4.118
    5) idx=3798  CookD=0.123410  leverage=0.054898  stud_resid=-4.373
    6) idx=9659  CookD=0.051227  leverage=0.051593  stud_resid=2.911
    7) idx=1080  CookD=0.037541  leverage=0.004830  stud_resid=-8.343
    8) idx=4023  CookD=0.036925  leverage=0.033731  stud_resid=-3.085
    9) idx=10332  CookD=0.036688  leverage=0.033101  stud_resid=-3.106
    10) idx=2308  CookD=0.026171  leverage=0.047587  stud_resid=-2.171

    For each top row, weâ€™ll classify it like:
	â€¢	â€œHigh CookD because leverage is hugeâ€
	â€¢	â€œHigh CookD because residual is hugeâ€
	â€¢	â€œBoth â†’ very influentialâ€

    Weâ€™ll read each row like:
	â€¢	Leverage: â€œhow unusual are the inputs (X)?â€
	â€¢	Studentized residual: â€œhow big is the error (standardized)?â€
	â€¢	Cookâ€™s D: â€œoverall influence = (unusual X) + (big error) â†’ how much the model can change if we remove itâ€

    1) idx=2757 â€” CookD=2.00, leverage=0.576, stud_resid=3.638

        Diagnosis: extreme leverage + large error â†’ very influential
        This is the most dangerous type:
            â€¢	unusual X and wrong prediction
            â€¢	can pull coefficients strongly

    2) idx=2580 â€” CookD=1.90, leverage=0.403, stud_resid=5.034

        Diagnosis: extreme leverage + very large error â†’ very influential
        Same as #1, even more error.

    âœ… These two are â€œred alertâ€ points.

    â¸»

    3) idx=225 â€” CookD=0.485, leverage=0.117, stud_resid=-5.732

        Diagnosis: high leverage + very large error (underprediction)
        Less leverage than #1/#2 but still insanely high vs normal.

    â¸»

    4) idx=10876 â€” CookD=0.136, leverage=0.067, stud_resid=4.118

        Diagnosis: moderately high leverage + large error
        Still influential.

    5) idx=3798 â€” CookD=0.123, leverage=0.055, stud_resid=-4.373

     Diagnosis: moderately high leverage + large error

    6) idx=9659 â€” CookD=0.051, leverage=0.052, stud_resid=2.911

        Diagnosis: high leverage + moderate-to-large error
        Influential mainly because leverage is high.

    â¸»

    7) idx=1080 â€” CookD=0.0375, leverage=0.00483, stud_resid=-8.343

        Diagnosis: huge error but leverage is not extreme (still > average, but not crazy).
        This is the â€œbig residualâ€ type:
            â€¢	model is very wrong for this point
            â€¢	but because X isnâ€™t super unusual, removing it wonâ€™t rotate the whole model as much as #1/#2.

    Still worth inspecting because |stud_resid| = 8.3 is enormous.

    â¸»

    8) idx=4023 â€” CookD=0.0369, leverage=0.0337, stud_resid=-3.085

        Diagnosis: moderate leverage + large error

    9) idx=10332 â€” CookD=0.0367, leverage=0.0331, stud_resid=-3.106

        Diagnosis: moderate leverage + large error

    10) idx=2308 â€” CookD=0.0262, leverage=0.0476, stud_resid=-2.171

        Diagnosis: higher leverage + moderate error
        Influence mostly from leverage.

    â¸»

    Summary diagnosis (what we learned today)

    Whatâ€™s driving Cookâ€™s D in our data?

    Mostly leverage.

    Look at #1 and #2:
        â€¢	leverage 0.576 and 0.403 are unbelievably high.
    Thatâ€™s why CookD is huge.

    What does that mean?

    We likely have a handful of training rows with extreme feature combinations that are not typical of the dataset. 
    They can distort the fitted coefficients

 np.argsort(cooks_d)[-top_k:][::-1] -->  what we are doing here

    What we want

        We want the indices (row numbers) of the top_k largest Cookâ€™s Distance values â€” i.e., the most influential points.

        cooks_d is an array like:
            â€¢	cooks_d[0] = Cookâ€™s D for row 0
            â€¢	cooks_d[1] = Cookâ€™s D for row 1
            â€¢	â€¦
        So we need the row indices of the biggest values.

    â¸»

    Step 1: np.argsort(cooks_d)

    argsort does not return sorted values.
    It returns the indices that would sort the array.

    example:
        cooks_d = [0.2, 0.05, 1.3, 0.4]
        np.argsort(cooks_d)  -> [1, 0, 3, 2]

    Why?
	â€¢	cooks_d[1] = 0.05 (smallest)
	â€¢	cooks_d[0] = 0.2
	â€¢	cooks_d[3] = 0.4
	â€¢	cooks_d[2] = 1.3 (largest)

    So after argsort, we have indices in ascending order of Cookâ€™s D.

    â¸»

    Step 2: [-top_k:]

    This slices the last top_k indices from that sorted list.

    Since the list is in ascending order:
        â€¢	the last top_k correspond to the largest Cookâ€™s D values

    So now we have â€œthe indices of the biggest Cookâ€™s D rowsâ€, but still in ascending order.

    â¸»

    Step 3: [::-1]

    This reverses the slice.

    So now we have the indices in descending order:
        â€¢	biggest Cookâ€™s D first
        â€¢	then second biggest
        â€¢	etc.

    â¸»

    Final result

    top_idx becomes something like:
    [2757, 2580, 225, 10876, ...]

    These are the row indices in the training set with the highest influence.
    
'''


#=========================================================
# Summarization in simple words
#=========================================================
'''
    We used statsmodels OLS and explicitly added the intercept using sm.add_constant(X_train), then used ols.get_influence() to compute influence diagnostics. 
    
    From the influence output we examined three metrics: 
        * studentized residuals, 
        * leverage (hat values), and 
        * Cookâ€™s Distance. 
        
    Studentized residuals are residuals scaled by their estimated standard deviation (a standardized error), 

    where |SR|>2 is worth inspecting and |SR|>3 is very large. 
    Average leverage is roughly (p+1)/n (with p features and n rows), and 
    a common Cookâ€™s D flag is 4/n. 
    
    We ranked the top 10 most influential points by Cookâ€™s D and saw that 
    * high influence typically comes from high leverage (unusual X), large standardized residuals (big error), or both. 
    * We learned that â€œhigh Cookâ€™s Dâ€ means a point can significantly affect model parameters,
      but it doesnâ€™t automatically mean the point is wrong or should be removed.
'''